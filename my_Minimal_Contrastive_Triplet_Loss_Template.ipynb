{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triplet Loss Scaffold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "class TripletDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        # Create a dictionary mapping from label to indices with that label\n",
    "        self.label_to_indices = defaultdict(list)\n",
    "        for idx, label in enumerate(labels):\n",
    "            self.label_to_indices[label].append(idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        anchor = self.data[idx]\n",
    "        anchor_label = self.labels[idx]\n",
    "        positive_idx = idx\n",
    "        while positive_idx == idx:\n",
    "            positive_idx = np.random.choice(self.label_to_indices[anchor_label])\n",
    "        positive = self.data[positive_idx]\n",
    "        \n",
    "        # Ensure the negative label is different from the anchor label\n",
    "        negative_label = anchor_label\n",
    "        while negative_label == anchor_label:\n",
    "            negative_label = np.random.choice(list(self.label_to_indices.keys()))\n",
    "        negative_idx = np.random.choice(self.label_to_indices[negative_label])\n",
    "        negative = self.data[negative_idx]\n",
    "\n",
    "        return anchor, positive, negative\n",
    "\n",
    "# Example data\n",
    "data = np.random.randn(100, 3, 32, 32)  # 100 samples of 3x32x32 images\n",
    "labels = np.random.randint(0, 10, 100)  # 100 random labels ranging from 0 to 9\n",
    "\n",
    "# Create the dataset\n",
    "triplet_dataset = TripletDataset(data, labels)\n",
    "triplet_loader = torch.utils.data.DataLoader(triplet_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Iterate through the dataset\n",
    "for anchors, positives, negatives in triplet_loader:\n",
    "    # Your training code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, anchor, positive, negative):\n",
    "        positive_distance = torch.nn.functional.pairwise_distance(anchor, positive)\n",
    "        negative_distance = torch.nn.functional.pairwise_distance(anchor, negative)\n",
    "        loss = torch.mean(torch.relu(positive_distance - negative_distance + self.margin))\n",
    "        return loss\n",
    "\n",
    "# Example usage:\n",
    "# loss_fn = TripletLoss(margin=1.0)\n",
    "# anchor, positive, negative are the outputs from the network for the anchor, positive, and negative samples respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimal Triplet Loss Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "class TextTripletDataset(Dataset):\n",
    "    def __init__(self, phrases, labels, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            phrases (list): List of text phrases.\n",
    "            labels (list): List of corresponding labels.\n",
    "            transform (callable, optional): Optional transform to be applied on the text sample.\n",
    "        \"\"\"\n",
    "        self.phrases = phrases\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.label_to_indices = self._create_label_to_indices()\n",
    "        self.vectorizer = CountVectorizer()\n",
    "        self.vectorized_phrases = self.vectorizer.fit_transform(phrases).toarray()\n",
    "\n",
    "    def _create_label_to_indices(self):\n",
    "        \"\"\"Creates a dictionary to map labels to indices of samples with that label.\"\"\"\n",
    "        label_to_indices = {}\n",
    "        for index, label in enumerate(self.labels):\n",
    "            if label not in label_to_indices:\n",
    "                label_to_indices[label] = []\n",
    "            label_to_indices[label].append(index)\n",
    "        return label_to_indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.phrases)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        anchor_phrase_vector = self.vectorized_phrases[index]\n",
    "        anchor_label = self.labels[index]\n",
    "        \n",
    "        # Set positive sample (same label)\n",
    "        positive_index = index\n",
    "        while positive_index == index:\n",
    "            positive_index = random.choice(self.label_to_indices[anchor_label])\n",
    "        positive_phrase_vector = self.vectorized_phrases[positive_index]\n",
    "\n",
    "        # Set negative sample (different label)\n",
    "        negative_label = random.choice(list(self.label_to_indices.keys()))\n",
    "        while negative_label == anchor_label:\n",
    "            negative_label = random.choice(list(self.label_to_indices.keys()))\n",
    "        negative_index = random.choice(self.label_to_indices[negative_label])\n",
    "        negative_phrase_vector = self.vectorized_phrases[negative_index]\n",
    "\n",
    "        return (torch.tensor(anchor_phrase_vector, dtype=torch.float32),\n",
    "                torch.tensor(positive_phrase_vector, dtype=torch.float32),\n",
    "                torch.tensor(negative_phrase_vector, dtype=torch.float32))\n",
    "\n",
    "# Example usage:\n",
    "# phrases = [\"I love dogs\", \"I love cats\", \"I hate dogs\", \"I hate cats\"]\n",
    "# labels = [0, 1, 2, 3]  # Assign numerical labels\n",
    "# dataset = TextTripletDataset(phrases, labels)\n",
    "# dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, anchor, positive, negative):\n",
    "        positive_distance = F.pairwise_distance(anchor, positive)\n",
    "        negative_distance = F.pairwise_distance(anchor, negative)\n",
    "        losses = torch.relu(positive_distance - negative_distance + self.margin)\n",
    "        return losses.mean()\n",
    "\n",
    "# Example usage with a sample model:\n",
    "# model = SampleModel()  # Define your model here\n",
    "# criterion = TripletLoss(margin=1.0)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "# for epoch in range(num_epochs):\n",
    "#     for anchor, positive, negative in dataloader:\n",
    "#         anchor_output = model(anchor)\n",
    "#         positive_output = model(positive)\n",
    "#         negative_output = model(negative)\n",
    "#         loss = criterion(anchor_output, positive_output, negative_output)\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contrastive Loss Scaffold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "\n",
    "class ContrastiveDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data (list of tuples): List of (image, label) tuples.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.label_to_indices = self._create_label_to_indices()\n",
    "\n",
    "    def _create_label_to_indices(self):\n",
    "        \"\"\"Creates a dictionary to map labels to indices of samples with that label.\"\"\"\n",
    "        label_to_indices = {}\n",
    "        for index, (_, label) in enumerate(self.data):\n",
    "            if label not in label_to_indices:\n",
    "                label_to_indices[label] = []\n",
    "            label_to_indices[label].append(index)\n",
    "        return label_to_indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img1, label1 = self.data[index]\n",
    "        \n",
    "        # Randomly decide to pick a positive or negative pair\n",
    "        if random.random() < 0.5:\n",
    "            # Positive sample\n",
    "            positive_index = index\n",
    "            while positive_index == index:\n",
    "                positive_index = random.choice(self.label_to_indices[label1])\n",
    "            img2, label2 = self.data[positive_index]\n",
    "        else:\n",
    "            # Negative sample\n",
    "            negative_label = random.choice(list(self.label_to_indices.keys()))\n",
    "            while negative_label == label1:\n",
    "                negative_label = random.choice(list(self.label_to_indices.keys()))\n",
    "            negative_index = random.choice(self.label_to_indices[negative_label])\n",
    "            img2, label2 = self.data[negative_index]\n",
    "\n",
    "        if self.transform:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "\n",
    "        return (img1, img2), (label1, label2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = torch.nn.functional.pairwise_distance(output1, output2)\n",
    "        loss_contrastive = torch.mean(\n",
    "            (1 - label) * torch.pow(euclidean_distance, 2) +\n",
    "            (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)\n",
    "        )\n",
    "        return loss_contrastive\n",
    "\n",
    "# Example usage:\n",
    "# loss_fn = ContrastiveLoss(margin=1.0)\n",
    "# output1, output2 are the outputs from the two branches of the Siamese network\n",
    "# label is 0 if the inputs are from the same class and 1 otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimal Contrastive Loss Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "class TextContrastiveDataset(Dataset):\n",
    "    def __init__(self, phrases, labels, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            phrases (list): List of text phrases.\n",
    "            labels (list): List of corresponding labels.\n",
    "            transform (callable, optional): Optional transform to be applied on the text sample.\n",
    "        \"\"\"\n",
    "        self.phrases = phrases\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.label_to_indices = self._create_label_to_indices()\n",
    "        self.vectorizer = CountVectorizer()\n",
    "        self.vectorized_phrases = self.vectorizer.fit_transform(phrases).toarray()\n",
    "\n",
    "    def _create_label_to_indices(self):\n",
    "        \"\"\"Creates a dictionary to map labels to indices of samples with that label.\"\"\"\n",
    "        label_to_indices = {}\n",
    "        for index, label in enumerate(self.labels):\n",
    "            if label not in label_to_indices:\n",
    "                label_to_indices[label] = []\n",
    "            label_to_indices[label].append(index)\n",
    "        return label_to_indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.phrases)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        phrase1 = self.vectorized_phrases[index]\n",
    "        label1 = self.labels[index]\n",
    "        \n",
    "        # Randomly decide to pick a positive or negative pair\n",
    "        if random.random() < 0.5:\n",
    "            # Positive sample\n",
    "            positive_index = index\n",
    "            while positive_index == index:\n",
    "                positive_index = random.choice(self.label_to_indices[label1])\n",
    "            phrase2 = self.vectorized_phrases[positive_index]\n",
    "            label2 = label1\n",
    "        else:\n",
    "            # Negative sample\n",
    "            negative_label = random.choice(list(self.label_to_indices.keys()))\n",
    "            while negative_label == label1:\n",
    "                negative_label = random.choice(list(self.label_to_indices.keys()))\n",
    "            negative_index = random.choice(self.label_to_indices[negative_label])\n",
    "            phrase2 = self.vectorized_phrases[negative_index]\n",
    "            label2 = negative_label\n",
    "\n",
    "        return (torch.tensor(phrase1, dtype=torch.float32), torch.tensor(phrase2, dtype=torch.float32)), torch.tensor(int(label1 == label2), dtype=torch.float32)\n",
    "\n",
    "# Example usage:\n",
    "# phrases = [\"I love dogs\", \"I love cats\", \"I hate dogs\", \"I hate cats\"]\n",
    "# labels = [0, 1, 2, 3]  # Assign numerical labels\n",
    "# dataset = TextContrastiveDataset(phrases, labels)\n",
    "# dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        loss_contrastive = torch.mean((1 - label) * torch.pow(euclidean_distance, 2) +\n",
    "                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "\n",
    "        return loss_contrastive\n",
    "\n",
    "# Example usage with a sample model:\n",
    "# model = SampleModel()  # Define your model here\n",
    "# criterion = ContrastiveLoss(margin=1.0)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "# for epoch in range(num_epochs):\n",
    "#     for (data1, data2), label in dataloader:\n",
    "#         output1 = model(data1)\n",
    "#         output2 = model(data2)\n",
    "#         loss = criterion(output1, output2, label)\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
