{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polars Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with Hashed Unique IDs:\n",
      "shape: (3, 3)\n",
      "┌───────────┬───────┬─────────────────────────────────┐\n",
      "│ unique_id ┆ value ┆ unique_id_hashed                │\n",
      "│ ---       ┆ ---   ┆ ---                             │\n",
      "│ i64       ┆ str   ┆ str                             │\n",
      "╞═══════════╪═══════╪═════════════════════════════════╡\n",
      "│ 1         ┆ A     ┆ 6b86b273ff34fce19d6b804eff5a3f… │\n",
      "│ 2         ┆ B     ┆ d4735e3a265e16eee03f59718b9b5d… │\n",
      "│ 3         ┆ C     ┆ 4e07408562bedb8b60ce05c1decfe3… │\n",
      "└───────────┴───────┴─────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import hashlib\n",
    "\n",
    "# Function to convert text to SHA-256 hash\n",
    "def text_to_sha256(text):\n",
    "    # Ensure the input is converted to string and encoded to bytes\n",
    "    return hashlib.sha256(str(text).encode('utf-8')).hexdigest()\n",
    "\n",
    "# Initialize the DataFrame\n",
    "df = pl.DataFrame({\n",
    "    'unique_id': [1, 2, 3],\n",
    "    'value': ['A', 'B', 'C']\n",
    "})\n",
    "\n",
    "# Apply the hashing function to the 'unique_id' column\n",
    "df_hashed = df.with_columns(\n",
    "    df['unique_id'].map_elements(text_to_sha256, return_dtype=pl.Utf8).alias('unique_id_hashed')\n",
    ")\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(\"DataFrame with Hashed Unique IDs:\")\n",
    "print(df_hashed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame:\n",
      "shape: (6, 2)\n",
      "┌───────────┬───────────┐\n",
      "│ unique_id ┆ value     │\n",
      "│ ---       ┆ ---       │\n",
      "│ i64       ┆ str       │\n",
      "╞═══════════╪═══════════╡\n",
      "│ 1         ┆ A         │\n",
      "│ 2         ┆ B_updated │\n",
      "│ 3         ┆ C_updated │\n",
      "│ 4         ┆ D_new     │\n",
      "│ 6         ┆ F_new     │\n",
      "│ 5         ┆ E         │\n",
      "└───────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Initialize sample DataFrames\n",
    "df = pl.DataFrame({\n",
    "    'unique_id': [1, 2, 3,5],\n",
    "    'value': ['A', 'B', 'C', 'E']\n",
    "})\n",
    "\n",
    "df_new = pl.DataFrame({\n",
    "    'unique_id': [1, 2, 3, 4,6],\n",
    "    'value': ['A','B_updated', 'C_updated', 'D_new', 'F_new']\n",
    "})\n",
    "\n",
    "# Use 'full' join to merge DataFrames on 'unique_id'\n",
    "merged_df = df.join(df_new, on='unique_id', how='full', suffix='_new')\n",
    "\n",
    "df = merged_df.with_columns(\n",
    "    pl.when(pl.col(\"unique_id_new\").is_null())\n",
    "    .then(pl.col(\"unique_id\"))\n",
    "    .otherwise(pl.col(\"unique_id_new\"))\n",
    "    .alias('unique_id'),\n",
    "\n",
    "    pl.when(pl.col(\"value_new\").is_null())\n",
    "    .then(pl.col(\"value\"))\n",
    "    .otherwise(pl.col(\"value_new\"))\n",
    "    .alias('value')\n",
    ").select(['unique_id', 'value'])\n",
    "\n",
    "\n",
    "# Print the merged DataFrame\n",
    "print(\"Merged DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# updated_rows_filter = (merged_df['value'] != merged_df['value_new']) & merged_df['value_new'].is_not_null()\n",
    "# updated_rows = updated_rows_filter.sum()\n",
    "# print(\"Number of updated rows:\", updated_rows)\n",
    "# inserted_rows = df_new.select('unique_id').join(df, on='unique_id', how='anti').shape[0]\n",
    "# print(f\"Number of inserted rows: {inserted_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (6, 4)\n",
      "┌───────────┬───────────┬───────────────┬───────────┐\n",
      "│ unique_id ┆ value     ┆ unique_id_new ┆ value_new │\n",
      "│ ---       ┆ ---       ┆ ---           ┆ ---       │\n",
      "│ i64       ┆ str       ┆ i64           ┆ str       │\n",
      "╞═══════════╪═══════════╪═══════════════╪═══════════╡\n",
      "│ 1         ┆ A         ┆ 1             ┆ A         │\n",
      "│ 2         ┆ B_updated ┆ 2             ┆ B_updated │\n",
      "│ 3         ┆ C_updated ┆ 3             ┆ C_updated │\n",
      "│ 4         ┆ D_new     ┆ 4             ┆ D_new     │\n",
      "│ 6         ┆ F_new     ┆ 6             ┆ F_new     │\n",
      "│ 5         ┆ E         ┆ null          ┆ null      │\n",
      "└───────────┴───────────┴───────────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "merged_df = df.join(df_new, on='unique_id', how='full', suffix='_new')\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_new.index.intersection(original_df.index.to_list())=Index([2, 3], dtype='int64', name='unique_id')\n",
      "Inserted rows: 1\n",
      "Final DataFrame:\n",
      "   unique_id      value\n",
      "0          1          A\n",
      "1          2  B_updated\n",
      "2          3  C_updated\n",
      "3          4          D\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize the DataFrames\n",
    "df = pd.DataFrame({\n",
    "    'unique_id': [1, 2, 3],\n",
    "    'value': ['A', 'B', 'C']\n",
    "})\n",
    "\n",
    "df_new = pd.DataFrame({\n",
    "    'unique_id': [2, 3, 4],\n",
    "    'value': ['B_updated', 'C_updated', 'D']\n",
    "})\n",
    "\n",
    "# Set 'unique_id' as the index for both DataFrames\n",
    "df.set_index('unique_id', inplace=True)\n",
    "df_new.set_index('unique_id', inplace=True)\n",
    "\n",
    "# Copy the original DataFrame to use for the updated row count\n",
    "original_df = df.copy()\n",
    "\n",
    "# Update the DataFrame (UPSERT existing rows)\n",
    "df.update(df_new)\n",
    "\n",
    "# Identify updated rows by comparing the values\n",
    "updated_rows = df_new.index.intersection(original_df.index).size\n",
    "\n",
    "# Combine the DataFrames (this will add new rows)\n",
    "df_combined = df.combine_first(df_new)\n",
    "\n",
    "# Count the number of inserted rows by finding new indices\n",
    "inserted_rows = df_combined.index.difference(original_df.index).size\n",
    "\n",
    "# Reset index to make 'unique_id' a column again\n",
    "df_combined.reset_index(inplace=True)\n",
    "\n",
    "# Print results\n",
    "# print(f\"Updated rows: {updated_rows}\")\n",
    "print(f\"{df_new.index.intersection(original_df.index.to_list())=}\")\n",
    "print(f\"Inserted rows: {inserted_rows}\")\n",
    "print(\"Final DataFrame:\")\n",
    "print(df_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted rows: 1\n",
      "Final DataFrame:\n",
      "   unique_id      value\n",
      "0          1          A\n",
      "1          2  B_updated\n",
      "2          3  C_updated\n",
      "3          4          D\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize the DataFrames\n",
    "df = pd.DataFrame({\n",
    "    'unique_id': [1, 2, 3],\n",
    "    'value': ['A', 'B', 'C']\n",
    "})\n",
    "\n",
    "df_new = pd.DataFrame({\n",
    "    'unique_id': [2, 3, 4],\n",
    "    'value': ['B_updated', 'C_updated', 'D']\n",
    "})\n",
    "\n",
    "# Set 'unique_id' as the index for both DataFrames\n",
    "df.set_index('unique_id', inplace=True)\n",
    "df_new.set_index('unique_id', inplace=True)\n",
    "\n",
    "# Copy the original DataFrame to use for the updated row count\n",
    "original_df = df.copy()\n",
    "\n",
    "# Update the DataFrame (UPSERT existing rows)\n",
    "df.update(df_new)\n",
    "\n",
    "# Identify updated rows by comparing the values\n",
    "# updated_rows = (df.loc[df_new.index.intersection(original_df.index)] != original_df).any(axis=1).sum()\n",
    "\n",
    "# Combine the DataFrames (this will add new rows)\n",
    "df_combined = df.combine_first(df_new)\n",
    "\n",
    "# Count the number of inserted rows by finding new indices\n",
    "inserted_rows = df_combined.index.difference(original_df.index).size\n",
    "\n",
    "# Reset index to make 'unique_id' a column again\n",
    "df_combined.reset_index(inplace=True)\n",
    "\n",
    "# Print results\n",
    "# print(f\"Updated rows: {updated_rows}\")\n",
    "print(f\"Inserted rows: {inserted_rows}\")\n",
    "print(\"Final DataFrame:\")\n",
    "print(df_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of updated rows: 2\n",
      "Upserted DataFrame:\n",
      "   unique_id      value\n",
      "0          1          A\n",
      "1          2  B_updated\n",
      "2          3  C_updated\n",
      "3          4          D\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize sample DataFrames\n",
    "df = pd.DataFrame({\n",
    "    'unique_id': [1, 2, 3],\n",
    "    'value': ['A', 'B', 'C']\n",
    "})\n",
    "\n",
    "df_new = pd.DataFrame({\n",
    "    'unique_id': [2, 3, 4],\n",
    "    'value': ['B_updated', 'C_updated', 'D']\n",
    "})\n",
    "\n",
    "# Perform UPSERT operation\n",
    "df.set_index('unique_id', inplace=True)\n",
    "df_new.set_index('unique_id', inplace=True)\n",
    "\n",
    "# Keep a copy of the original DataFrame for comparison\n",
    "original_df = df.copy()\n",
    "\n",
    "# Update existing rows\n",
    "df.update(df_new)\n",
    "\n",
    "# Count the updated rows\n",
    "updated_rows = (df != original_df).any(axis=1).sum()\n",
    "\n",
    "# Append new rows\n",
    "df = df.combine_first(df_new)\n",
    "\n",
    "# Reset index to ensure unique_id is a column\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "# Print the number of updated rows\n",
    "print(\"Number of updated rows:\", updated_rows)\n",
    "\n",
    "# Print the final DataFrame\n",
    "print(\"Upserted DataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of updated rows: 2\n",
      "Number of inserted rows: 1\n",
      "Upserted DataFrame:\n",
      "shape: (4, 2)\n",
      "┌───────────┬───────────┐\n",
      "│ unique_id ┆ value     │\n",
      "│ ---       ┆ ---       │\n",
      "│ i64       ┆ str       │\n",
      "╞═══════════╪═══════════╡\n",
      "│ 2         ┆ B_updated │\n",
      "│ 3         ┆ C_updated │\n",
      "│ null      ┆ D         │\n",
      "│ 1         ┆ A         │\n",
      "└───────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Initialize sample DataFrames\n",
    "df = pl.DataFrame({\n",
    "    'unique_id': [1, 2, 3],\n",
    "    'value': ['A', 'B', 'C']\n",
    "})\n",
    "\n",
    "df_new = pl.DataFrame({\n",
    "    'unique_id': [2, 3, 4],\n",
    "    'value': ['B_updated', 'C_updated', 'D']\n",
    "})\n",
    "\n",
    "# Perform a full join on 'unique_id' to identify and update existing rows\n",
    "joined_df = df.join(df_new, on='unique_id', how='full', suffix='_new')\n",
    "\n",
    "# Determine updated rows where the 'value' in df is different from 'df_new'\n",
    "updated_rows_filter = (joined_df['value'] != joined_df['value_new']) & joined_df['value_new'].is_not_null()\n",
    "updated_rows = updated_rows_filter.sum()\n",
    "\n",
    "# Update values where available\n",
    "df_updated = joined_df.with_columns([\n",
    "    pl.when(joined_df['value_new'].is_null())\n",
    "    .then(joined_df['value'])\n",
    "    .otherwise(joined_df['value_new'])\n",
    "    .alias('final_value')\n",
    "])\n",
    "\n",
    "# Select columns and resolve renaming\n",
    "df_upserted = df_updated.select(['unique_id', 'final_value']).rename({'final_value': 'value'})\n",
    "\n",
    "# Count the number of inserted rows\n",
    "# Inserted rows are determined by rows in df_new not appearing in the original df\n",
    "inserted_rows = df_new.select('unique_id').join(df, on='unique_id', how='anti').shape[0]\n",
    "\n",
    "# Print the counts and the final DataFrame\n",
    "print(f\"Number of updated rows: {updated_rows}\")\n",
    "print(f\"Number of inserted rows: {inserted_rows}\")\n",
    "print(\"Upserted DataFrame:\")\n",
    "print(df_upserted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of updated rows: 2\n",
      "Number of inserted rows: 1\n",
      "Upserted DataFrame:\n",
      "shape: (3, 2)\n",
      "┌───────────┬───────────┐\n",
      "│ unique_id ┆ value     │\n",
      "│ ---       ┆ ---       │\n",
      "│ i64       ┆ str       │\n",
      "╞═══════════╪═══════════╡\n",
      "│ 2         ┆ B_updated │\n",
      "│ 3         ┆ C_updated │\n",
      "│ 1         ┆ A         │\n",
      "└───────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Initialize sample DataFrames\n",
    "df = pl.DataFrame({\n",
    "    'unique_id': [1, 2, 3],\n",
    "    'value': ['A', 'B', 'C']\n",
    "})\n",
    "\n",
    "df_new = pl.DataFrame({\n",
    "    'unique_id': [2, 3, 4],\n",
    "    'value': ['B_updated', 'C_updated', 'D']\n",
    "})\n",
    "\n",
    "# Perform a full join on 'unique_id' to identify and update existing rows\n",
    "joined_df = df.join(df_new, on='unique_id', how='full', suffix='_new')\n",
    "\n",
    "# Update values where available\n",
    "df_updated = joined_df.with_columns([\n",
    "    pl.when(joined_df['value_new'].is_null())\n",
    "    .then(joined_df['value'])\n",
    "    .otherwise(joined_df['value_new'])\n",
    "    .alias('final_value')\n",
    "])\n",
    "\n",
    "# Select the resultant columns and correct the index\n",
    "df_upserted = df_updated.select(['unique_id', 'final_value']).rename({'final_value': 'value'})\n",
    "\n",
    "# Set 'unique_id' as a column instead of allowing it to become an index by avoiding any drop errors\n",
    "df_upserted = df_upserted.filter(df_upserted['unique_id'].is_not_null())\n",
    "\n",
    "# Determine updated rows where the 'value' in df is different from 'df_new'\n",
    "updated_rows_filter = (joined_df['value'] != joined_df['value_new']) & joined_df['value_new'].is_not_null()\n",
    "updated_rows = updated_rows_filter.sum()\n",
    "\n",
    "# Count the number of inserted rows\n",
    "inserted_rows = df_new.select('unique_id').join(df, on='unique_id', how='anti').shape[0]\n",
    "\n",
    "# Print the counts and the final DataFrame\n",
    "print(f\"Number of updated rows: {updated_rows}\")\n",
    "print(f\"Number of inserted rows: {inserted_rows}\")\n",
    "print(\"Upserted DataFrame:\")\n",
    "print(df_upserted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of updated rows: 2\n",
      "Number of inserted rows: 1\n",
      "Upserted DataFrame:\n",
      "shape: (4, 2)\n",
      "┌───────────┬───────────┐\n",
      "│ unique_id ┆ value     │\n",
      "│ ---       ┆ ---       │\n",
      "│ i64       ┆ str       │\n",
      "╞═══════════╪═══════════╡\n",
      "│ 2         ┆ B_updated │\n",
      "│ 3         ┆ C_updated │\n",
      "│ null      ┆ D         │\n",
      "│ 1         ┆ A         │\n",
      "└───────────┴───────────┘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kj/gvh5xsgn2rzcw5xtdqct3_ch0000gn/T/ipykernel_88051/1499459814.py:16: DeprecationWarning: Use of `how='outer'` should be replaced with `how='full'`.\n",
      "  df.join(\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Initialize sample DataFrames\n",
    "df = pl.DataFrame({\n",
    "    'unique_id': [1, 2, 3],\n",
    "    'value': ['A', 'B', 'C']\n",
    "})\n",
    "\n",
    "df_new = pl.DataFrame({\n",
    "    'unique_id': [2, 3, 4],\n",
    "    'value': ['B_updated', 'C_updated', 'D']\n",
    "})\n",
    "\n",
    "# Perform upsert operation in a more concise way\n",
    "df_upserted = (\n",
    "    df.join(\n",
    "        df_new,\n",
    "        on='unique_id',\n",
    "        how='outer'\n",
    "    ).with_columns(\n",
    "        pl.coalesce('value_right', 'value').alias('value')\n",
    "    ).select(['unique_id', 'value'])\n",
    ")\n",
    "\n",
    "# Calculate metrics\n",
    "updated_rows = (\n",
    "    df.join(df_new, on='unique_id')\n",
    "    .filter(pl.col('value') != pl.col('value_right'))\n",
    "    .shape[0]\n",
    ")\n",
    "\n",
    "inserted_rows = df_new.join(df, on='unique_id', how='anti').shape[0]\n",
    "\n",
    "# Print results\n",
    "print(f\"Number of updated rows: {updated_rows}\")\n",
    "print(f\"Number of inserted rows: {inserted_rows}\")\n",
    "print(\"Upserted DataFrame:\")\n",
    "print(df_upserted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of updated rows: 2\n",
      "Number of inserted rows: 1\n",
      "Upserted DataFrame:\n",
      "shape: (4, 2)\n",
      "┌───────────┬───────────┐\n",
      "│ unique_id ┆ value     │\n",
      "│ ---       ┆ ---       │\n",
      "│ i64       ┆ str       │\n",
      "╞═══════════╪═══════════╡\n",
      "│ 2         ┆ B_updated │\n",
      "│ 3         ┆ C_updated │\n",
      "│ null      ┆ D         │\n",
      "│ 1         ┆ A         │\n",
      "└───────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Initialize sample DataFrames\n",
    "df = pl.DataFrame({\n",
    "    'unique_id': [1, 2, 3],\n",
    "    'value': ['A', 'B', 'C']\n",
    "})\n",
    "\n",
    "df_new = pl.DataFrame({\n",
    "    'unique_id': [2, 3, 4],\n",
    "    'value': ['B_updated', 'C_updated', 'D']\n",
    "})\n",
    "\n",
    "# Perform upsert operation using how='full'\n",
    "df_upserted = (\n",
    "    df.join(\n",
    "        df_new,\n",
    "        on='unique_id',\n",
    "        how='full'\n",
    "    ).with_columns(\n",
    "        pl.coalesce('value_right', 'value').alias('value')\n",
    "    ).select(['unique_id', 'value'])\n",
    ")\n",
    "\n",
    "# Calculate metrics\n",
    "updated_rows = (\n",
    "    df.join(df_new, on='unique_id')\n",
    "    .filter(pl.col('value') != pl.col('value_right'))\n",
    "    .shape[0]\n",
    ")\n",
    "\n",
    "inserted_rows = df_new.join(df, on='unique_id', how='anti').shape[0]\n",
    "\n",
    "# Print results\n",
    "print(f\"Number of updated rows: {updated_rows}\")\n",
    "print(f\"Number of inserted rows: {inserted_rows}\")\n",
    "print(\"Upserted DataFrame:\")\n",
    "print(df_upserted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of updated rows: 2\n",
      "Number of inserted rows: 1\n",
      "Upserted DataFrame:\n",
      "shape: (4, 2)\n",
      "┌───────────┬───────────┐\n",
      "│ unique_id ┆ value     │\n",
      "│ ---       ┆ ---       │\n",
      "│ i64       ┆ str       │\n",
      "╞═══════════╪═══════════╡\n",
      "│ null      ┆ D         │\n",
      "│ 1         ┆ A         │\n",
      "│ 2         ┆ B_updated │\n",
      "│ 3         ┆ C_updated │\n",
      "└───────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Initialize sample DataFrames\n",
    "df = pl.DataFrame({\n",
    "    'unique_id': [1, 2, 3],\n",
    "    'value': ['A', 'B', 'C']\n",
    "})\n",
    "\n",
    "df_new = pl.DataFrame({\n",
    "    'unique_id': [2, 3, 4],\n",
    "    'value': ['B_updated', 'C_updated', 'D']\n",
    "})\n",
    "\n",
    "# Perform upsert operation with proper indexing\n",
    "df_upserted = (\n",
    "    df.join(\n",
    "        df_new,\n",
    "        on='unique_id',\n",
    "        how='full'\n",
    "    ).with_columns(\n",
    "        pl.coalesce('value_right', 'value').alias('value')\n",
    "    ).select(['unique_id', 'value'])\n",
    "    .sort('unique_id')  # Add sorting to maintain index order\n",
    ")\n",
    "\n",
    "# Calculate metrics\n",
    "updated_rows = (\n",
    "    df.join(df_new, on='unique_id')\n",
    "    .filter(pl.col('value') != pl.col('value_right'))\n",
    "    .shape[0]\n",
    ")\n",
    "\n",
    "inserted_rows = df_new.join(df, on='unique_id', how='anti').shape[0]\n",
    "\n",
    "# Print results\n",
    "print(f\"Number of updated rows: {updated_rows}\")\n",
    "print(f\"Number of inserted rows: {inserted_rows}\")\n",
    "print(\"Upserted DataFrame:\")\n",
    "print(df_upserted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Upsert and Merge with Delta Lake Tables in Python Polars](https://stuffbyyuki.com/upsert-and-merge-with-delta-lake-tables-in-python-polars/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 3)\n",
      "┌─────┬────────┬───────┐\n",
      "│ key ┆ letter ┆ value │\n",
      "│ --- ┆ ---    ┆ ---   │\n",
      "│ i64 ┆ str    ┆ i64   │\n",
      "╞═════╪════════╪═══════╡\n",
      "│ 1   ┆ a      ┆ 100   │\n",
      "│ 2   ┆ b      ┆ 200   │\n",
      "│ 3   ┆ c      ┆ 300   │\n",
      "└─────┴────────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "df = pl.DataFrame(\n",
    "    {\n",
    "        'key': [1, 2, 3],\n",
    "        'letter': ['a', 'b', 'c'],\n",
    "        'value': [100, 200, 300]\n",
    "    }\n",
    ")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "deltalake is not installed\n\nPlease run: pip install deltalake",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m output_table_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./my_delta_lake_table\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_delta\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_table_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moverwrite\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe target Delta Lake table output:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, pl\u001b[38;5;241m.\u001b[39mread_delta(output_table_path))\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/setfit_env/lib/python3.11/site-packages/polars/dataframe/frame.py:4275\u001b[0m, in \u001b[0;36mDataFrame.write_delta\u001b[0;34m(self, target, mode, overwrite_schema, storage_options, delta_write_options, delta_merge_options)\u001b[0m\n\u001b[1;32m   4263\u001b[0m     issue_deprecation_warning(\n\u001b[1;32m   4264\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe parameter `overwrite_schema` for `write_delta` is deprecated.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4265\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Use the parameter `delta_write_options` instead and pass `\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mschema_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}`.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   4266\u001b[0m         version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.20.14\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   4267\u001b[0m     )\n\u001b[1;32m   4269\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpolars\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdelta\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m   4270\u001b[0m     _check_for_unsupported_types,\n\u001b[1;32m   4271\u001b[0m     _check_if_delta_available,\n\u001b[1;32m   4272\u001b[0m     _resolve_delta_lake_uri,\n\u001b[1;32m   4273\u001b[0m )\n\u001b[0;32m-> 4275\u001b[0m \u001b[43m_check_if_delta_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4277\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeltalake\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeltaTable, write_deltalake\n\u001b[1;32m   4279\u001b[0m _check_for_unsupported_types(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtypes)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/setfit_env/lib/python3.11/site-packages/polars/io/delta.py:419\u001b[0m, in \u001b[0;36m_check_if_delta_available\u001b[0;34m()\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _DELTALAKE_AVAILABLE:\n\u001b[1;32m    418\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeltalake is not installed\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPlease run: pip install deltalake\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 419\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(msg)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: deltalake is not installed\n\nPlease run: pip install deltalake"
     ]
    }
   ],
   "source": [
    "output_table_path = './my_delta_lake_table'\n",
    "\n",
    "df.write_delta(output_table_path, mode='overwrite')\n",
    "print('The target Delta Lake table output:\\n', pl.read_delta(output_table_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 3)\n",
      "┌─────┬────────┬───────┐\n",
      "│ key ┆ letter ┆ value │\n",
      "│ --- ┆ ---    ┆ ---   │\n",
      "│ i64 ┆ str    ┆ i64   │\n",
      "╞═════╪════════╪═══════╡\n",
      "│ 2   ┆ b      ┆ 200   │\n",
      "│ 3   ┆ d      ┆ 300   │\n",
      "│ 4   ┆ d      ┆ 400   │\n",
      "└─────┴────────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "df_col_updated_and_row_deleted = (\n",
    "    df\n",
    "    .with_columns(\n",
    "        pl.when(pl.col('letter')=='c')  # update a column \n",
    "        .then(pl.lit('d'))\n",
    "        .otherwise(pl.col('letter'))  \n",
    "        .alias('letter')\n",
    "    )\n",
    "    .filter(pl.col('key') != 1)  # delete a row \n",
    ")\n",
    "\n",
    "df_with_changes = (\n",
    "    pl.concat(\n",
    "        [\n",
    "            df_col_updated_and_row_deleted,\n",
    "            pl.DataFrame({'key': 4, 'letter': 'd', 'value': 400})  # a new row\n",
    "        ],\n",
    "        how='vertical'\n",
    "    )\n",
    ")\n",
    "print(df_with_changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "deltalake is not installed\n\nPlease run: pip install deltalake",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m (\n\u001b[1;32m      2\u001b[0m     \u001b[43mdf_with_changes\u001b[49m\n\u001b[0;32m----> 3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_delta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_table_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmerge\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelta_merge_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpredicate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msource.key = target.key\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msource_alias\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msource\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtarget_alias\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtarget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;241m.\u001b[39mwhen_matched_update_all()\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;241m.\u001b[39mwhen_not_matched_insert_all()\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;241m.\u001b[39mwhen_not_matched_by_source_delete()\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;241m.\u001b[39mexecute()\n\u001b[1;32m     16\u001b[0m )  \n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/setfit_env/lib/python3.11/site-packages/polars/dataframe/frame.py:4275\u001b[0m, in \u001b[0;36mDataFrame.write_delta\u001b[0;34m(self, target, mode, overwrite_schema, storage_options, delta_write_options, delta_merge_options)\u001b[0m\n\u001b[1;32m   4263\u001b[0m     issue_deprecation_warning(\n\u001b[1;32m   4264\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe parameter `overwrite_schema` for `write_delta` is deprecated.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4265\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Use the parameter `delta_write_options` instead and pass `\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mschema_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}`.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   4266\u001b[0m         version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.20.14\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   4267\u001b[0m     )\n\u001b[1;32m   4269\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpolars\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdelta\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m   4270\u001b[0m     _check_for_unsupported_types,\n\u001b[1;32m   4271\u001b[0m     _check_if_delta_available,\n\u001b[1;32m   4272\u001b[0m     _resolve_delta_lake_uri,\n\u001b[1;32m   4273\u001b[0m )\n\u001b[0;32m-> 4275\u001b[0m \u001b[43m_check_if_delta_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4277\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeltalake\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeltaTable, write_deltalake\n\u001b[1;32m   4279\u001b[0m _check_for_unsupported_types(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtypes)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/setfit_env/lib/python3.11/site-packages/polars/io/delta.py:419\u001b[0m, in \u001b[0;36m_check_if_delta_available\u001b[0;34m()\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _DELTALAKE_AVAILABLE:\n\u001b[1;32m    418\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeltalake is not installed\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPlease run: pip install deltalake\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 419\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(msg)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: deltalake is not installed\n\nPlease run: pip install deltalake"
     ]
    }
   ],
   "source": [
    "(\n",
    "    df_with_changes\n",
    "    .write_delta(\n",
    "        output_table_path,\n",
    "        mode='merge',\n",
    "        delta_merge_options={\n",
    "            'predicate': 'source.key = target.key',\n",
    "            'source_alias': 'source',\n",
    "            'target_alias': 'target',\n",
    "        },\n",
    "    )\n",
    "    .when_matched_update_all()\n",
    "    .when_not_matched_insert_all()\n",
    "    .when_not_matched_by_source_delete()\n",
    "    .execute()\n",
    ")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
